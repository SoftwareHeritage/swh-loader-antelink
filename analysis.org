#+title: Analysis about Antepedia contents

All those numbers are actually reproducible through the antelink db.

NB: Those numbers do not account for the corrupted data on sesi yet.
The computation of checksums for those contents (including corruption flag - mismatch
between sha1 name and actual sha1) is in progress on sesi.

* Nomenclatura

- content: swh's content table (duplicated from ours in softwareheritage db)
- content_sesi: a scan of sesi's antelink backup (exactly 314899904
- contents which is more than reality now ~> 280M)
- content_s3: `aws s3 ls` from antepedia's s3 bucket (exact listing of antepedia's s3 contents)
- content_s3_not_in_sesi: {s3} \ {sesi}
- content_s3_not_in_sesi_nor_swh: ({s3} \ {sesi}) \ {swh}

* Antelink content in s3 and not in sesi

{s3} \ {sesi}:
#+begin_src sql
antelink=# create materialized view content_s3_not_in_sesi
as select sha1, path
    from content_s3 as s3
    where not exists
      (select 1 from content_sesi as sesi where s3.sha1 = sesi.sha1);

SELECT 741797
#+end_src

Thus in compressed size (unit is bytes):
#+begin_src sql
antelink=# select sum(s3.length)
from content_s3_not_in_sesi s3notsesi
inner join content_s3 s3 on s3.sha1=s3notsesi.sha1;
    sum
------------
 3543013165
(1 row)
#+end_src

so ~3G.

* Antelink contents only in s3 and not in swh nor sesi

({s3} \ {sesi}) \ {swh}:
#+begin_src sql
antelink=# create materialized view content_s3_not_in_sesi_nor_in_swh
           as select sha1, path
           from content_s3_not_in_sesi as s3
           where not exists
           (select 1 from content as swh where s3.sha1 = swh.sha1);
SELECT 46
#+end_src

So apparently, the data that needs retrieval is already on sesi.

* Antelink contents in sesi but not in swh


{sesi} \ {swh}:
#+begin_src sql
antelink=# create materialized view content_sesi_not_in_swh
           as select sha1
           from content_sesi as sesi
           where not exists
           (select 1 from content as swh where sesi.sha1 = swh.sha1);
SELECT 207095510
#+end_src

Indeed!

* Missed backup-ed contents since disks crash

Table `content_sesi` contains contents from zack's scan and
compression routine.

Since then, inria admins mistakenly removed our hard disk bay (/antelink/store0 mount point).
So we miss 25 419 313 contents.

** Demonstration

Each of the following files contains on each line one filepath in the
corresponding store (/antelink/store{10,11,12,13,14,15,16,4,5,6,7,8,9}):
#+begin_src txt
   32269834 /antelink/store0/tmp-compute-checksums/file-store10.csv
    6353200 /antelink/store0/tmp-compute-checksums/file-store11.csv
    6356584 /antelink/store0/tmp-compute-checksums/file-store12.csv
    6192914 /antelink/store0/tmp-compute-checksums/file-store13.csv
   32262055 /antelink/store0/tmp-compute-checksums/file-store14.csv
   32268595 /antelink/store0/tmp-compute-checksums/file-store15.csv
    6352648 /antelink/store0/tmp-compute-checksums/file-store16.csv
   32236548 /antelink/store0/tmp-compute-checksums/file-store4.csv
   32246790 /antelink/store0/tmp-compute-checksums/file-store5.csv
   32230119 /antelink/store0/tmp-compute-checksums/file-store6.csv
   32264976 /antelink/store0/tmp-compute-checksums/file-store7.csv
   32249986 /antelink/store0/tmp-compute-checksums/file-store8.csv
    6196342 /antelink/store0/tmp-compute-checksums/file-store9.csv
  289480591 total
#+end_src

#+begin_src elisp
(- 314899904 289480591) ;; 25 419 313
#+end_src

* Hash computation running on sesi:

|---------+-----------+-----------+-----------+-----------+-------------|
| Store   |  Expected |    Actual |   Remains |      Done | db injected |
|---------+-----------+-----------+-----------+-----------+-------------|
| store10 |  32269834 |  32269834 |         0 |       100 |             |
| store11 |   6353200 |   6353200 |         0 |       100 | X           |
| store12 |   6356584 |   6095037 |    261547 | 95.885416 |             |
| store13 |   6192914 |   5970461 |    222453 | 96.407943 |             |
| store14 |  32262055 |  32262055 |         0 |       100 | X           |
| store15 |  32268595 |  32268595 |         0 |       100 | X           |
| store16 |   6352648 |   6352648 |         0 |       100 | X           |
| store4  |  32236548 |  15849673 |  16386875 | 49.166781 |             |
| store5  |  32246790 |  11973633 |  20273157 | 37.131240 |             |
| store6  |  32230119 |   8033977 |  24196142 | 24.926923 |             |
| store7  |  32264976 |   9000000 |  23264976 | 27.894024 |             |
| store8  |  32249986 |   9000000 |  23249986 | 27.906989 |             |
| store9  |   6196342 |   4272722 |   1923620 | 68.955555 |             |
|---------+-----------+-----------+-----------+-----------+-------------|
| total   | 289480591 | 179701835 | 109778756 | 62.077335 | 77236358    |
|---------+-----------+-----------+-----------+-----------+-------------|
#+TBLFM: $4=$2-$3::@15$2=vsum(@2$2..@14$2)::@15$3=vsum(@2$3..@14$3)::$5=(100*$3)/$2


db injection status:
#+begin_src sql
antelink=> select count(*) from content_sesi_all;
  count
----------
 77236358
(1 row)
#+end_src

(+ 6353200 32262055 32268595 6352648);; 77236498


The missing part must be an offset introduced after:
- one error that happened during hash computation (the content is then skipped without being written... fixed now)
- the main process stopped
- the resumption is taken using the number of lines being processed

Note: There remains:
- offset to consider
- huge file to deal with (~100)
- some files were issued problems when computation hash (2 for the moment)

** Estimated average speed

As of:
- Thu Feb 18 18:41:59 CET 2016, 126260951 hash computations done
- Fri Feb 19 09:44:29 CET 2016, 147911166 hash computations done

#+begin_src elisp
(require 'dash)
(require 'parse-time)

(defun swh-worker-to-time (str-date)
  "STR-DATE is a parseable string date.
Compute the time."
  (->> str-date
       parse-time-string
       (apply 'encode-time)))

(defun swh-worker-time-in-seconds-between (str-date1 str-date0)
  "Compute the seconds between STR-DATE1 and STR-DATE0.
They are both string parseable date time."
  (let ((t1 (swh-worker-to-time str-date1))
        (t0 (swh-worker-to-time str-date0)))
    (time-to-seconds (time-subtract t1 t0))))

(let ((seconds (swh-worker-time-in-seconds-between "Fri Feb 19 09:44:29 CET 2016" "Thu Feb 18 18:41:59 CET 2016")) ;; 54150.0
      (hashes-diff (- 147911166 126260951)))  ;; 21650215 hashes
    (/ hashes-diff seconds));; 399.81929824561405 hash/s
#+end_src
399.8 hashes/s

** Remains

So at current speed, remains ~4 days left
#+begin_src elisp
(/ 140859511 399.8);; 352324.939969985 seconds
(/ (/ 140859511 399.8) (* 60.0 60.0 24.0));; 4.077834953356308 day
#+end_src
